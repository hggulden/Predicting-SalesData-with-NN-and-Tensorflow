{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\gunsu\\Documents\\\\DL_Linkedin\\\\Ex_Files_TensorFlow\\\\Exercise Files\\\\04\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load training data set from CSV file\n",
    "training_data_df = pd.read_csv(\"sales_data_training.csv\", dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pull out columns for X (data to train with) and Y (value to predict)\n",
    "X_training = training_data_df.drop('total_earnings', axis=1).values\n",
    "Y_training = training_data_df[['total_earnings']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load testing data set from CSV file\n",
    "test_data_df = pd.read_csv(\"sales_data_test.csv\", dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pull out columns for X (data to train with) and Y (value to predict)\n",
    "X_testing = test_data_df.drop('total_earnings', axis=1).values\n",
    "Y_testing = test_data_df[['total_earnings']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All data needs to be scaled to a small range like 0 to 1 for the neural\n",
    "# network to work well. Create scalers for the inputs and outputs.\n",
    "X_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "Y_scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scale both the training inputs and outputs\n",
    "X_scaled_training = X_scaler.fit_transform(X_training)\n",
    "Y_scaled_training = Y_scaler.fit_transform(Y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training and test data are scaled with the same scaler.\n",
    "X_scaled_testing = X_scaler.transform(X_testing)\n",
    "Y_scaled_testing = Y_scaler.transform(Y_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define model parameters\n",
    "learning_rate=0.001\n",
    "training_epochs=100\n",
    "display_step=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#define how many inputs and outputs are in the NN\n",
    "number_of_inputs=9\n",
    "number_of_outputs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_inputs=9\n",
    "number_of_outputs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define how many neurons we want in each layer\n",
    "layer_1_nodes=50\n",
    "layer_2_nodes=100\n",
    "layer_3_nodes=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "#Section one:defining layers of NN itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#input layer: None tells tf that tf can accept batch of any size\n",
    "with tf.variable_scope('input'):\n",
    "    X=tf.placeholder(tf.float32,shape=(None,number_of_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 1\n",
    "with tf.variable_scope('layer_1'):\n",
    "    weights = tf.get_variable(name=\"weights1\", shape=[number_of_inputs, layer_1_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases1\", shape=[layer_1_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_1_output = tf.nn.relu(tf.matmul(X, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 2\n",
    "with tf.variable_scope('layer_2', reuse=None):\n",
    "    weights = tf.get_variable(name=\"weights2\", shape=[layer_1_nodes, layer_2_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases2\", shape=[layer_2_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_2_output = tf.nn.relu(tf.matmul(layer_1_output, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Layer 3\n",
    "with tf.variable_scope('layer_3'):\n",
    "    weights = tf.get_variable(name=\"weights3\", shape=[layer_2_nodes, layer_3_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases3\", shape=[layer_3_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_3_output = tf.nn.relu(tf.matmul(layer_2_output, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output Layer\n",
    "with tf.variable_scope('output'):\n",
    "    weights = tf.get_variable(name=\"weights4\", shape=[layer_3_nodes, number_of_outputs], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases4\", shape=[number_of_outputs], initializer=tf.zeros_initializer())\n",
    "    prediction = tf.matmul(layer_3_output, weights) + biases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Section Two: Define the cost function of the neural network that will measure prediction accuracy during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('cost'):\n",
    "    Y=tf.placeholder(tf.float32,shape=(None,1))\n",
    "    cost=tf.reduce_mean(tf.squared_difference(prediction,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Optimizer tat will run to opt.to train the NN\n",
    "with tf.variable_scope('train'):\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize a summary operation that we can run tf operations\n",
    "with tf.variable_scope('logging'):\n",
    "    tf.summary.scalar('current_cost',cost)\n",
    "    summary=tf.summary.merge_all()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0430876 0.0430876\n",
      "5 0.024254 0.024254\n",
      "10 0.00999026 0.00999026\n",
      "15 0.0102059 0.0102059\n",
      "20 0.0056957 0.0056957\n",
      "25 0.00444549 0.00444549\n",
      "30 0.00357561 0.00357561\n",
      "35 0.00226845 0.00226845\n",
      "40 0.00169878 0.00169878\n",
      "45 0.00130227 0.00130227\n",
      "50 0.000978923 0.000978923\n",
      "55 0.000779158 0.000779158\n",
      "60 0.00060873 0.00060873\n",
      "65 0.000474125 0.000474125\n",
      "70 0.000377004 0.000377004\n",
      "75 0.000305243 0.000305243\n",
      "80 0.000251688 0.000251688\n",
      "85 0.000212215 0.000212215\n",
      "90 0.000181756 0.000181756\n",
      "95 0.000158934 0.000158934\n",
      "Training is complete!\n",
      "final_training_cost: 0.00014327651297207922\n",
      "final_testing_cost: 0.00014327651297207922\n"
     ]
    }
   ],
   "source": [
    "#Initialize a session to run TensorFlow graph (operations)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    #run the global vaiable initializer to initialize all variables and layers_lway\n",
    "    #initialze with tf.global_variables_initializer\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    #create log file writers to record training progress\n",
    "    #will store training and testing log data separately\n",
    "    training_writer=tf.summary.FileWriter(\"./logs/training\",session.graph)\n",
    "    testing_writer=tf.summary.FileWriter(\"./logs/testing\",session.graph)\n",
    "    \n",
    "    #run the optimizer many times to train the NN\n",
    "    #One epoch is one full run through the training data set\n",
    "    for epoch in range(training_epochs):\n",
    "        #Feed in the training data set and do one step NN training\n",
    "        session.run(optimizer,feed_dict={X:X_scaled_training,Y:Y_scaled_training})\n",
    "        if epoch%5==0:\n",
    "            training_cost,training_summary=session.run([cost,summary],feed_dict={X:X_scaled_training,Y:Y_scaled_training})\n",
    "            testing_cost,testing_summary=session.run([cost,summary],feed_dict={X:X_scaled_training,Y:Y_scaled_training})\n",
    "            #write the current training status to a log file\n",
    "            training_writer.add_summary(training_summary,epoch)\n",
    "            testing_writer.add_summary(testing_summary,epoch)\n",
    "            \n",
    "            print(epoch,training_cost,testing_cost)\n",
    "        #print the current training status the the screen\n",
    "    print('Training is complete!')\n",
    "\n",
    "    final_training_cost=session.run(cost,feed_dict={X:X_scaled_training,Y:Y_scaled_training})\n",
    "    final_testing_cost=session.run(cost,feed_dict={X:X_scaled_training,Y:Y_scaled_training}) \n",
    "    \n",
    "    print(\"final_training_cost: {}\".format(final_training_cost))\n",
    "    print(\"final_testing_cost: {}\".format(final_testing_cost))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
